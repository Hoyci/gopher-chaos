# Gopher Chaos üå™Ô∏è

### Por que o Gopher Chaos existe?
Sistemas falham. √â uma certeza, n√£o uma probabilidade. Em arquiteturas de microservi√ßos, o sucesso de uma requisi√ß√£o depende de dezenas de fatores externos: lat√™ncia de rede, satura√ß√£o de CPU e falhas parciais.

Muitas vezes, nossos testes de unidade e integra√ß√£o cobrem o "caminho feliz", mas negligenciam como o sistema se comporta sob estresse. 

O Gopher Chaos foi criado para:

1. **Validar Timeouts**: Garantir que o cliente n√£o fique esperando infinitamente por uma resposta.
2. **Testar Circuit Breakers**: Verificar se sua aplica√ß√£o para de chamar um servi√ßo que est√° falhando sistematicamente.
3. **Expor Race Conditions**: A lat√™ncia vari√°vel frequentemente revela bugs de concorr√™ncia que n√£o aparecem em ambientes de baixa lat√™ncia.

### O Fluxo do Caos

Diferente de ferramentas que injetam falhas na camada de rede, o Gopher Chaos atua na camada de aplica√ß√£o via Interceptors gRPC. Isso permite um controle granular e visibilidade total dentro do c√≥digo Go.

## Como Utilizar

1. **Configura√ß√£o do Engine**

O core do projeto √© o ChaosConfig, onde voc√™ define a agressividade do seu teste.

```golang
cfg := chaos.ChaosConfig{
    Probability: 0.1, // 10% das requisi√ß√µes sofrer√£o interven√ß√£o
    Latency: chaos.ChaosConfigLatency{
        Min: 100 * time.Millisecond,
        Max: 2 * time.Second,
    },
    Error: codes.Internal, // Erro gRPC a ser injetado
}
```

2. **Registro do Interceptor**

Basta adicionar o interceptor na cria√ß√£o do seu servidor gRPC:
```golang
chaosEngine := chaos.NewChaos(cfg)
interceptor := interceptors.NewInterceptor(chaosEngine)

s := grpc.NewServer(
    grpc.UnaryInterceptor(interceptor.UnaryInterceptor),
    grpc.StreamInterceptor(interceptor.StreamInterceptor),
)
```

## Estrutura do Projeto
`pkg/chaos`: O motor que decide quando e como falhar.

`pkg/interceptors`: A ponte entre o motor de caos e o gRPC (Unary e Stream).

`example/`: Implementa√ß√£o de um UserService para testes pr√°ticos de carga e streaming.

## Decis√µes de Arquitetura
Este trecho do documento explica o racioc√≠nio por tr√°s das escolhas implementadas no projeto.

### A Escolha da Camada: gRPC Interceptors
Implementar o caos via interceptores (middleware) foi uma escolha estrat√©gica para garantir a **Separation of concerns**.

**Transpar√™ncia**: A l√≥gica de neg√≥cio no `handlers/user_grpc.go` n√£o sabe que o caos existe.

**Abrang√™ncia**: Conseguimos interceptar tanto chamadas simples (Unary) quanto fluxos de dados cont√≠nuos (Stream), garantindo que falhas possam ocorrer no meio de uma transmiss√£o de dados longa.

### Inje√ß√£o de Lat√™ncia (Sleep Progressivo)
A implementa√ß√£o em `pkg/interceptors/interceptor.go` utiliza um select com `time.NewTimer`.

* **Por que n√£o apenas falhar?**

Falhas instant√¢neas s√£o f√°ceis de tratar. O cen√°rio mais perigoso em produ√ß√£o √© o "Gray Failure", onde o servi√ßo est√° lento, consumindo threads do chamador e causando um efeito cascata.

* **Respeito ao Contexto**: 

O uso de case ` <-ctx.Done()` no interceptor √© crucial. Se o cliente desistir da requisi√ß√£o antes do timer do caos terminar, n√≥s liberamos os recursos imediatamente, simulando o comportamento real de um servidor sob press√£o.

## Erros gRPC Espec√≠ficos
O motor permite configurar qual `codes.Code` ser√° retornado.

* **Motiva√ß√£o**: Testar se o cliente diferencia um `INTERNAL` (erro de c√≥digo) de um `UNAVAILABLE` (erro de infra). Isso √© vital para configurar pol√≠ticas de retry inteligentes ‚Äî voc√™ n√£o deve dar retry em um erro 4xx, mas deve em um 5xx.

##  Concorr√™ncia e Performance (sync.Pool)
Em `pkg/chaos/engine.go`, utilizamos um sync.Pool para gerenciar as inst√¢ncias de `rand.Rand`.

* `O Problema`: O gerador de n√∫meros aleat√≥rios global do Go (rand.Float64()) sofre de conten√ß√£o de lock em sistemas de alta performance.
* `A Solu√ß√£o`: Ao usar um pool de geradores locais, garantimos que a inje√ß√£o de caos n√£o se torne ela mesma o gargalo do sistema durante testes de carga massivos.

## Suporte a Streaming
A implementa√ß√£o do `wrappedStream` em `pkg/interceptors/stream.go` √© o ponto do projeto em que lidamos com streams gRPC. 

Nesse cen√°rio, a conex√£o pode ficar aberta por minutos e o caos n√£o pode ocorrer apenas no in√≠cio. 

Ao interceptar `SendMsg` e `RecvMsg`, podemos simular uma conex√£o que come√ßa bem e degrada no meio do processo, for√ßando o desenvolvedor a tratar erros dentro do loop de `Recv()`.
